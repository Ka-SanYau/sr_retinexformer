# ===================================
# General Settings
# ===================================
name: SR_MSResnet_x4_without_base # Name of the experiment
model_type: SRModel             # Use the SRModel type for paired image tasks
scale: 4                        # No scaling for low-light enhancement
num_gpu: 1                      # Set num_gpu: 0 for CPU mode
manual_seed: 100                # Random seed for reproducibility

# ===================================
# Dataset and Data Loader Settings
# ===================================
datasets:
  train:
    name: TrainSet
    type: PairedImageDataset
    dataroot_gt: /home/qc-lab/research/datasets/SR/div2k/DIV2K_train_HR_sub  # Path for ground-truth (bright) images
    dataroot_lq: /home/qc-lab/research/datasets/SR/div2k/DIV2K_train_LR_bicubic/X4_sub # Path for low-light input images
    use_hflip: true            # Enable horizontal flipping for data augmentation
    use_rot: true              # Enable rotation for data augmentation
    geometric_augs: true       # Enable geometric augmentations
    # gt_size: 256               # Crop size for training patches
    filename_tmpl: '{}'        # Template for filenames
    io_backend:
      type: disk               # Use disk-based IO

    # Data loader
    use_shuffle: true          # Shuffle the training data
    num_worker_per_gpu: 1      # Number of workers per GPU
    batch_size_per_gpu: 8      # Batch size per GPU

    ### -------------Progressive training--------------------------
    mini_batch_sizes: [8,4,4,4,4,4]             # Batch size per gpu
    iters: [10000,10000,10000,10000,10000,10000]
    gt_size: 256 # 1280  1600  # Max patch size for progressive training
    gt_sizes: [128,152,172,184,192,256] # [128,160,192,256,320,384]  # Patch sizes for progressive training.
    ### ------------------------------------------------------------


    dataset_enlarge_ratio: 1   # No dataset enlargement (default)
    prefetch_mode: ~           # Disable prefetching

  # val:
  #   name: ValSet
  #   type: PairedImageDataset
  #   dataroot_gt: /home/qc-lab/research/datasets/NTIRE_LLIE/eval/high  # Path for validation ground-truth images
  #   dataroot_lq: /home/qc-lab/research/datasets/NTIRE_LLIE/eval/low   # Path for validation low-light images
  #   io_backend:
  #     type: disk               # Use disk-based IO
  val: # validation 数据集的设置
    name: Set5 # 数据集名称
    type: PairedImageDataset # 数据集的类型
    # 以下属性是灵活的, 类似训练数据集
    dataroot_gt: /home/qc-lab/research/datasets/SR/benchmark/Set5/GTmod12
    dataroot_lq: /home/qc-lab/research/datasets/SR/benchmark/Set5/LRbicx4
    io_backend:
      type: disk

  val_2: # 另外一个 validation 数据集
    name: Set14
    type: PairedImageDataset
    dataroot_gt: /home/qc-lab/research/datasets/SR/benchmark/Set14/GTmod12
    dataroot_lq: /home/qc-lab/research/datasets/SR/benchmark/Set14/LRbicx4
    io_backend:
      type: disk

# ===================================
# Network Structure
# ===================================
network_g:
  type: MSRResNet_Real_SR                   # Use the EDSR architecture
  num_in_ch: 3                 # Input channels (e.g., RGB has 3)
  num_out_ch: 3                # Output channels (e.g., RGB has 3)
  # num_feat: 96                 # Number of intermediate feature channels (default: 64)
  # num_block: 16                # Number of residual blocks (default: 16)
  upscale: 4                  # No upscaling for enhancement
  # res_scale: 1                 # Scale factor for residuals in residual blocks
  # poemap: true
  # poe_enhance: false
  # poe_3: false
  # img_range: 255.0             # Image range for normalization
  # rgb_mean: [0.4488, 0.4371, 0.4040]  # Mean values for RGB normalization (DIV2K dataset)

# ===================================
# Path Settings
# ===================================
path:
  pretrain_network_g: ~        # Path to pretrained model (leave empty to train from scratch)
  strict_load_g: true          # Strictly load pretrained model weights
  resume_state: ~              # Path to resume training state (leave empty for new training)

# ===================================
# Training Settings
# ===================================
train:
  total_iter: 60000           # Total number of training iterations
  warmup_iter: -1              # No warm-up phase
  use_grad_clip: true          # Clip gradients to avoid exploding gradients

  scheduler:
    type: CosineAnnealingRestartCyclicLR
    periods: [25000, 35000]    # Two cycles of 75,000 iterations each
    restart_weights: [1, 1]    # Equal weights for both cycles
    eta_mins: [!!float 1e-4, !!float 1e-6]   # Minimum learning rates for both cycles

  optim_g:
    type: Adam                 # Use Adam optimizer
    lr: !!float 2e-4           # Learning rate
    betas: [0.9, 0.999]        # Beta parameters for Adam optimizer

  # Loss function
  pixel_opt:
    type: L1Loss               # Use L1 loss for pixel-level supervision
    loss_weight: 1             # Weight for the L1 loss
    reduction: mean            # Reduction method for loss

  # Loss function
  # abc_opt:
  #   type: ceL1Loss             # Specify your custom loss function here
  #   loss_weight: 0.5           # Weight for the loss
  #   reduction: mean            # Reduction method: 'none', 'mean', or 'sum'

# ===================================
# Validation Settings
# ===================================
val:
  val_freq: !!float 1e3        # Validate every 1000 iterations
  save_img: true               # Save validation results
  rgb2bgr: true                # Convert RGB to BGR for saving images
  use_image: true              # Save images during validation
  max_minibatch: 8             # Maximum number of mini-batches to process

  metrics:
    psnr:                      # PSNR metric
      type: calculate_psnr
      crop_border: 4           # No cropping for PSNR calculation
      test_y_channel: true    # Use RGB channels for PSNR calculation
      
    ssim:                      # SSIM metric
      type: calculate_ssim
      crop_border: 4           # No cropping for SSIM calculation
      test_y_channel: true    # Use RGB channels for SSIM calculation

    lpips:                     # LPIPS metric
      type: calculate_lpips
      crop_border: 0           # No cropping for LPIPS calculation
      test_y_channel: false    # Use RGB channels for LPIPS calculation
      better: lower            # Lower LPIPS is better

# ===================================
# Logging Settings
# ===================================
logger:
  print_freq: 100              # Print logs every 100 iterations
  save_checkpoint_freq: !!float 5e3  # Save model checkpoints every 5000 iterations
  use_tb_logger: true          # Use TensorBoard for logging
  wandb:
    project: ~                 # Name of the WandB project (optional)
    resume_id: ~               # Resume ID for WandB (optional)

# ===================================
# Distributed Training Settings
# ===================================
dist_params:
  backend: nccl               # Backend for distributed training
  port: 29500                 # Port for distributed training communication